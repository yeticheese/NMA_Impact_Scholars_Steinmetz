{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "execution": {},
    "id": "xalMnXHJL_Wz"
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import emd\n",
    "import tarfile\n",
    "import io\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from icecream import ic\n",
    "import neurodsp.filt as dsp\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Directories\n",
    "Set the working directory as well as access to the main LFP dataset and supplementary dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "execution": {},
    "id": "zGp78Gb2L_W0"
   },
   "source": [
    "# Set the current working directory\n",
    "cwd = os.chdir(r\"C:\\Python Work Directory\\NMA_Impact_Scholars_Steinmetz\")\n",
    "\n",
    "# Access to the Steinmetz LFP dataset\n",
    "# lfp_dat = r\"E:\\Steinmetz_Dataset\"\n",
    "lfp_dat  = r\"C:\\Python Work Directory\\NMA_Impact_Scholars_Steinmetz\\data\\examples\"\n",
    "\n",
    "# @title Data retrieval\n",
    "data_directory = r'data\\spikeAndBehavioralData'\n",
    "\n",
    "# test_dataset\n",
    "test_LFP = r\"Cori_2016-12-18\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(os.path.join(os.getcwd(),data_directory))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Brain Regions of Interest"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hpc = [\"CA1\", \"CA3\", \"DG\", \"SUB\"]\n",
    "pfc = [\"ACA\", \"ILA\", \"PL\",\"RSP\"]\n",
    "region_loop = hpc + pfc\n",
    "region_select = 'CA1'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Power spectrum functions"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Defining file iterator (for later use)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "walker = os.walk(os.path.join(os.getcwd(),data_directory))\n",
    "for root, dirs, files in walker:\n",
    "    print(root)\n",
    "    print(dirs)\n",
    "    print(files)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### .npy file loader from tarball"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def npy_loader(filename:str)-> np.ndarray:\n",
    "    '''\n",
    "    Numpy loader function for .npy in tarball (.tar) packages.\n",
    "    \n",
    "    :param filename: str\n",
    "    :return: np.ndarray \n",
    "    '''\n",
    "    try:\n",
    "        npy_file = tar.extractfile(filename)\n",
    "        if npy_file is not None:\n",
    "            npy_file_content = npy_file.read()\n",
    "            \n",
    "            # Check file size to confirm it's not empty or corrupted\n",
    "            if len(npy_file_content) == 0:\n",
    "                raise ValueError(f\"The .npy file '{filename}' is empty or corrupted.\")\n",
    "            \n",
    "            # Load .npy file from memory using BytesIO\n",
    "            np_data = np.load(io.BytesIO(npy_file_content))\n",
    "            return np_data\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Could not find or extract the file: {probe_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading .npy file: {e}\")\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "alldata_tar_path = os.path.join(os.getcwd(),data_directory,test_LFP + r\".tar\")\n",
    "with tarfile.open(alldata_tar_path, 'r') as tar:\n",
    "    print(tar.getnames())\n",
    "    \n",
    "    brain_loc_filename = [name for name in tar.getnames()[:5] if name.endswith('.tsv')][0]\n",
    "    probe_desc_filename = [name for name in tar.getnames() if name.endswith('rawFilename.tsv')][0]\n",
    "    probe_filename = [name for name in tar.getnames() if name.endswith('channels.probe.npy')][0]\n",
    "    raw_Row_filename = [name for name in tar.getnames() if name.endswith('channels.rawRow.npy')][0]\n",
    "    site_filename = [name for name in tar.getnames() if name.endswith('channels.site.npy')][0]\n",
    "    site_pos_filename = [name for name in tar.getnames() if name.endswith('channels.sitePositions.npy')][0]\n",
    "    \n",
    "    \n",
    "    brain_loc = pd.read_csv(tar.extractfile(brain_loc_filename), sep='\\t')\n",
    "    probe_desc = pd.read_csv(tar.extractfile(probe_desc_filename), sep='\\t')\n",
    "    probe = npy_loader(probe_filename)\n",
    "    raw_Row = npy_loader(raw_Row_filename)\n",
    "    site = npy_loader(site_filename)\n",
    "    site_pos = npy_loader(site_pos_filename)\n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "brain_loc.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "brain_loc.query(f'allen_ontology == \"{region_select}\"')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "probe_desc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "brain_loc['probe'] = probe\n",
    "brain_loc['site'] = site\n",
    "brain_loc[['site_pos_x','site_pos_y']] = site_pos\n",
    "brain_loc['raw_Row'] = raw_Row"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "brain_loc.query(f'allen_ontology == \"{region_select}\"') ",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Discovering the Channel Labelling Scheme"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the scatter plot using Plotly Express\n",
    "fig = px.scatter(brain_loc.query('probe == 0'),\n",
    "                 x='site_pos_x',\n",
    "                 y='site_pos_y',\n",
    "                 color='site',\n",
    "                 title='Brain Location Scatter Plot',\n",
    "                 width=1200,  # Equivalent to figsize=(20,10)\n",
    "                 height=600)\n",
    "\n",
    "# Customize the layout if needed\n",
    "fig.update_layout(\n",
    "    title_x=0.5,  # Center the title\n",
    "    legend_title_text='Site',\n",
    "    # Add any additional layout customizations here\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the scatter plot using Plotly Express\n",
    "fig = px.scatter(brain_loc.query('probe == 0'),\n",
    "                 x='site_pos_x',\n",
    "                 y='site_pos_y',\n",
    "                 color='allen_ontology',\n",
    "                 title='Brain Location Scatter Plot',\n",
    "                 width=1200,  # Equivalent to figsize=(20,10)\n",
    "                 height=600)\n",
    "\n",
    "# Customize the layout if needed\n",
    "fig.update_layout(\n",
    "    title_x=0.5,  # Center the title\n",
    "    legend_title_text='Site',\n",
    "    # Add any additional layout customizations here\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Probe Selection\n",
    "\n",
    "Select the necessary probes that have recording sites of our brain regions of interest"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identify probe for CA1\n",
    "probe_select = brain_loc.query(f'allen_ontology == \"{region_select}\"')['probe'].unique() == np.array(probe_desc.index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TODO: Build a dataset loader that interacts with the online database\n",
    "\n",
    "# Path to your .tar file\n",
    "\n",
    "\n",
    "tar_path = os.path.join(lfp_dat,test_LFP + r\"_lfp.tar\")\n",
    "\n",
    "\n",
    "\n",
    "# Define the parameters based on the documentation\n",
    "num_channels = 385  # 385 channels as specified\n",
    "data_type = np.int16  # int16 data type\n",
    "sampling_rate = 2500  # 2500 Hz sampling rate\n",
    "\n",
    "# Open the .tar file and load the .bin file\n",
    "with tarfile.open(tar_path, 'r') as tar:\n",
    "    # Identify the .bin file (assuming there's only one)\n",
    "    bin_file_name = np.array(tar.getnames())[probe_select][0]\n",
    "    \n",
    "    \n",
    "    # Extract the .bin file to memory\n",
    "    bin_file = tar.extractfile(bin_file_name)\n",
    "    \n",
    "    # Determine the number of samples by dividing the file size by the number of channels\n",
    "    # and the size of each data point (2 bytes for int16)\n",
    "    file_size = tar.getmember(bin_file_name).size\n",
    "    num_samples = file_size // (num_channels * np.dtype(data_type).itemsize)\n",
    "    \n",
    "    # Read the .bin file in chunks if it's too large for memory\n",
    "    chunk_size = 1000000  # Set a reasonable chunk size\n",
    "    all_data = []\n",
    "    \n",
    "    while True:\n",
    "        # Read a chunk of data\n",
    "        data_chunk = np.frombuffer(bin_file.read(chunk_size * num_channels * np.dtype(data_type).itemsize), dtype=data_type)\n",
    "        if data_chunk.size == 0:\n",
    "            break\n",
    "        # Reshape the chunk to (num_channels, chunk_samples)\n",
    "        data_chunk = data_chunk.reshape(-1, num_channels).T\n",
    "        all_data.append(data_chunk)\n",
    "    \n",
    "    # Concatenate all chunks if the entire data needs to be loaded\n",
    "    reshaped_data = np.hstack(all_data)\n",
    "\n",
    "# At this point, reshaped_data contains the LFP data in shape (385, num_total_samples)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ic(reshaped_data.shape)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Synchronization Signal Channel\n",
    "When plotting Channel 385, we can observe that this channel contains our time events of stimulus being presented"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sampling_rate = 2500\n",
    "total_time = reshaped_data.shape[1]/sampling_rate\n",
    "time_points = np.linspace(0,total_time, reshaped_data.shape[1])\n",
    "time_points_ms = time_points*1000\n",
    "\n",
    "sync_signal_fig = px.line(\n",
    "    x=time_points_ms[:1000000],\n",
    "    y=reshaped_data[-1,:1000000],\n",
    "    labels={'x': 'Time (ms)', 'y': 'Amplitude (μV)'},\n",
    "    title='Synchronization Signal Time Series'\n",
    ")\n",
    "\n",
    "sync_signal_fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Plot of a random CA1 channel"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CA1_signal_fig = px.line(\n",
    "    x=time_points_ms[:1000000],\n",
    "    y=reshaped_data[-233,:1000000],\n",
    "    labels={'x': 'Time (ms)', 'y': 'Amplitude (μV)'},\n",
    "    title='CA1, Channel 233 Signal Time Series'\n",
    ")\n",
    "\n",
    "CA1_signal_fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Power Spectrum of CA1\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "select_channels = reshaped_data[brain_loc.query(f'allen_ontology == \"{region_select}\"')['raw_Row'].unique()]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "freqs, pspec = signal.welch(x = select_channels, fs = 2500, scaling = 'spectrum', nperseg = 4*1024)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors = px.colors.sequential.Viridis\n",
    "num_channels = len(pspec)\n",
    "color_indices = np.linspace(0, 1, num_channels)\n",
    "\n",
    "pspec_fig = go.Figure()\n",
    "\n",
    "# Create the figure\n",
    "for i, psd in enumerate(pspec):\n",
    "    pspec_fig.add_trace(go.Scatter(\n",
    "                            x=freqs,\n",
    "                            y=psd,\n",
    "                            mode='lines',\n",
    "                            line=dict(color=colors[int(color_indices[i] * (len(colors) - 1))]),\n",
    "    ))\n",
    "\n",
    "# Customize layout\n",
    "pspec_fig.update_layout(\n",
    "    title='Power Spectrum of CA1 channels',\n",
    "    width=1200,\n",
    "    height=600,\n",
    "    xaxis_title='Frequency (Hz)',\n",
    "    yaxis_title='Power',\n",
    "    yaxis_type='log'\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "pspec_fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retrieves the reference to subtract from the signal\n",
    "def CAR_filter(signal, mode ='mean'):\n",
    "    avg_ref = np.zeros((signal.shape[0],1))\n",
    "    if mode == 'mean':\n",
    "        avg_ref = np.mean(signal,axis=0)\n",
    "    if mode == 'median':\n",
    "        avg_ref = np.median(signal,axis=0)\n",
    "    return avg_ref"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "avg_ref = CAR_filter(reshaped_data[:-1], mode='median')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Power spectrum after selecting the best HPC channel"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "name": "load_steinmetz_extra",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
