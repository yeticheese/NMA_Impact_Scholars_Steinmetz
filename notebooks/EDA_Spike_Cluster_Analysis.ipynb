{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:01:02.366547Z",
     "start_time": "2025-02-01T15:01:01.640037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "from scipy import signal\n",
    "from scipy.stats import zscore\n",
    "from icecream import ic\n",
    "import neurodsp.filt as dsp\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import dask.array as da\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import multiprocessing\n",
    "import sys\n",
    "from src.file_ops import npy_loader, get_probe_signals\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "from pathlib import Path\n"
   ],
   "id": "c7100dfc0e89cc59",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:18:39.326119Z",
     "start_time": "2025-02-01T15:18:39.323668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the current working directory\n",
    "cwd = os.chdir(r\"C:\\Python Work Directory\\NMA_Impact_Scholars_Steinmetz\")\n",
    "\n",
    "# @title Data retrieval\n",
    "data_directory = r'data\\spikeAndBehavioralData'\n",
    "\n",
    "# test_dataset\n",
    "test_LFP = r\"Cori_2016-12-17\""
   ],
   "id": "42096b6f6939cf00",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:18:39.334466Z",
     "start_time": "2025-02-01T15:18:39.326119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "walker = os.walk(os.path.join(os.getcwd(),data_directory))\n",
    "for root, dirs, files in walker:\n",
    "    print(root)\n",
    "    print(dirs)\n",
    "    for file in files:\n",
    "        print(file)"
   ],
   "id": "2bf149e36eb2efa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Python Work Directory\\NMA_Impact_Scholars_Steinmetz\\data\\spikeAndBehavioralData\n",
      "[]\n",
      "Cori_2016-12-14.tar\n",
      "Cori_2016-12-17.tar\n",
      "Cori_2016-12-18.tar\n",
      "Forssmann_2017-11-01.tar\n",
      "Forssmann_2017-11-02.tar\n",
      "Forssmann_2017-11-04.tar\n",
      "Forssmann_2017-11-05.tar\n",
      "Hench_2017-06-15.tar\n",
      "Hench_2017-06-16.tar\n",
      "Hench_2017-06-17.tar\n",
      "Hench_2017-06-18.tar\n",
      "Lederberg_2017-12-05.tar\n",
      "Lederberg_2017-12-06.tar\n",
      "Lederberg_2017-12-07.tar\n",
      "Lederberg_2017-12-08.tar\n",
      "Lederberg_2017-12-09.tar\n",
      "Lederberg_2017-12-10.tar\n",
      "Lederberg_2017-12-11.tar\n",
      "Moniz_2017-05-15.tar\n",
      "Moniz_2017-05-16.tar\n",
      "Moniz_2017-05-18.tar\n",
      "Muller_2017-01-07.tar\n",
      "Muller_2017-01-08.tar\n",
      "Muller_2017-01-09.tar\n",
      "Radnitz_2017-01-08.tar\n",
      "Radnitz_2017-01-09.tar\n",
      "Radnitz_2017-01-10.tar\n",
      "Radnitz_2017-01-11.tar\n",
      "Radnitz_2017-01-12.tar\n",
      "Richards_2017-10-29.tar\n",
      "Richards_2017-10-30.tar\n",
      "Richards_2017-10-31.tar\n",
      "Richards_2017-11-01.tar\n",
      "Richards_2017-11-02.tar\n",
      "Tatum_2017-12-06.tar\n",
      "Tatum_2017-12-07.tar\n",
      "Tatum_2017-12-08.tar\n",
      "Tatum_2017-12-09.tar\n",
      "Theiler_2017-10-11.tar\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:18:39.384233Z",
     "start_time": "2025-02-01T15:18:39.381218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_spikes_data(filename):\n",
    "    with tarfile.open(filename) as tar:\n",
    "        spikes = [name for name in tar.getnames() if name.startswith('spikes')]"
   ],
   "id": "4bf1a58f7ad4bd64",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:09:28.951263Z",
     "start_time": "2025-02-01T17:09:28.922911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Clusters:\n",
    "    depths: Optional[np.ndarray] = None\n",
    "    original_ids: Optional[np.ndarray] = None\n",
    "    peak_channel: Optional[np.ndarray] = None\n",
    "    probes: Optional[np.ndarray] = None\n",
    "    template_waveform_chans: Optional[np.ndarray] = None\n",
    "    template_waveforms: Optional[np.ndarray] = None\n",
    "    waveform_duration: Optional[np.ndarray] = None\n",
    "    phy_annotation: Optional[np.ndarray] = None\n",
    "\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the cluster data to a pandas DataFrame.\n",
    "        For multi-dimensional arrays, only the first dimension is used as the index,\n",
    "        and the remaining dimensions are stored as array objects in the cells.\n",
    "        \"\"\"\n",
    "        data_dict = {}\n",
    "        base_length = None\n",
    "\n",
    "        # Process each attribute\n",
    "        for attr_name, value in self.__dict__.items():\n",
    "            if value is not None:\n",
    "                if len(value.shape) == 1:\n",
    "                    # 1D arrays can be directly added\n",
    "                    data_dict[attr_name] = value\n",
    "                    if base_length is None:\n",
    "                        base_length = len(value)\n",
    "                else:\n",
    "                    # For multi-dimensional arrays, store them as objects\n",
    "                    # Each row will contain a slice of the array\n",
    "                    data_dict[attr_name] = [value[i] for i in range(value.shape[0])]\n",
    "                    if base_length is None:\n",
    "                        base_length = value.shape[0]\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def from_tar(cls, tar_path: str | Path) -> 'Clusters':\n",
    "        \"\"\"\n",
    "        Load cluster data from a tar file containing numpy arrays.\n",
    "\n",
    "        Args:\n",
    "            tar_path: Path to the tar file containing cluster data\n",
    "\n",
    "        Returns:\n",
    "            ClusterData instance with loaded arrays\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If tar file doesn't exist\n",
    "            ValueError: If expected cluster files are missing\n",
    "        \"\"\"\n",
    "        # if not os.path.exists(tar_path):\n",
    "        #     raise FileNotFoundError(f\"Tar file not found: {tar_path}\")\n",
    "\n",
    "        data = cls()\n",
    "\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            cluster_files = [name for name in tar.getnames() if name.startswith('clusters')]\n",
    "\n",
    "            # Mapping between file names and dataclass attributes\n",
    "            file_attr_map = {\n",
    "                'clusters.depths.npy': 'depths',\n",
    "                'clusters.originalIDs.npy': 'original_ids',\n",
    "                'clusters.peakChannel.npy': 'peak_channel',\n",
    "                'clusters.probes.npy': 'probes',\n",
    "                'clusters.templateWaveformChans.npy': 'template_waveform_chans',\n",
    "                'clusters.templateWaveforms.npy': 'template_waveforms',\n",
    "                'clusters.waveformDuration.npy': 'waveform_duration',\n",
    "                'clusters._phy_annotation.npy': 'phy_annotation'\n",
    "            }\n",
    "\n",
    "            # Extract and load each file\n",
    "            for file_name, attr_name in file_attr_map.items():\n",
    "                if file_name not in cluster_files:\n",
    "                    print(f\"Warning: {file_name} not found in tar archive\")\n",
    "                    continue\n",
    "\n",
    "                # try:\n",
    "                #     # Extract file to memory and load with numpy\n",
    "                #     member = tar.extractfile(file_name)\n",
    "                #     if member is None:\n",
    "                #         raise ValueError(f\"Could not extract {file_name}\")\n",
    "\n",
    "                array_data = npy_loader(tar,file_name)\n",
    "                setattr(data, attr_name, array_data)\n",
    "\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "@dataclass\n",
    "class Trials:\n",
    "    feedback_type: Optional[np.ndarray] = None\n",
    "    feedback_times: Optional[np.ndarray] = None\n",
    "    gocue_times: Optional[np.ndarray] = None\n",
    "    included: Optional[np.ndarray] = None\n",
    "    intervals: Optional[np.ndarray] = None\n",
    "    repNum: Optional[np.ndarray] = None\n",
    "    response_choice: Optional[np.ndarray] = None\n",
    "    response_times: Optional[np.ndarray] = None\n",
    "    contrast_left: Optional[np.ndarray] = None\n",
    "    constra_right: Optional[np.ndarray] = None\n",
    "    stimulus_times: Optional[np.ndarray] = None\n",
    "\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the Trials data to a pandas DataFrame.\n",
    "        For multi-dimensional arrays, only the first dimension is used as the index,\n",
    "        and the remaining dimensions are stored as array objects in the cells.\n",
    "        \"\"\"\n",
    "        data_dict = {}\n",
    "        base_length = None\n",
    "\n",
    "        # Process each attribute\n",
    "        for attr_name, value in self.__dict__.items():\n",
    "            if value is not None:\n",
    "                if len(value.shape) == 1:\n",
    "                    # 1D arrays can be directly added\n",
    "                    data_dict[attr_name] = value\n",
    "                    if base_length is None:\n",
    "                        base_length = len(value)\n",
    "                else:\n",
    "                    # For multi-dimensional arrays, store them as objects\n",
    "                    # Each row will contain a slice of the array\n",
    "                    data_dict[attr_name] = [value[i] for i in range(value.shape[0])]\n",
    "                    if base_length is None:\n",
    "                        base_length = value.shape[0]\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def from_tar(cls, tar_path: str | Path) -> 'Trials':\n",
    "        \"\"\"\n",
    "        Load cluster data from a tar file containing numpy arrays.\n",
    "\n",
    "        Args:\n",
    "            tar_path: Path to the tar file containing cluster data\n",
    "\n",
    "        Returns:\n",
    "            ClusterData instance with loaded arrays\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If tar file doesn't exist\n",
    "            ValueError: If expected cluster files are missing\n",
    "        \"\"\"\n",
    "        # if not os.path.exists(tar_path):\n",
    "        #     raise FileNotFoundError(f\"Tar file not found: {tar_path}\")\n",
    "\n",
    "        data = cls()\n",
    "\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            trial_files = [name for name in tar.getnames() if name.startswith('trials')]\n",
    "\n",
    "            # Mapping between file names and dataclass attributes\n",
    "            file_attr_map = {\n",
    "                'trials.feedbackType.npy': 'feedback_type',\n",
    "                'trials.feedback_times.npy': 'feedback_times',\n",
    "                'trials.goCue_times.npy': 'gocue_times',\n",
    "                'trials.included.npy': 'included',\n",
    "                'trials.intervals.npy': 'intervals',\n",
    "                'trials.repNum.npy': 'repNum',\n",
    "                'trials.response_choice.npy': 'response_choice',\n",
    "                'trials.response_times.npy': 'response_times',\n",
    "                'trials.visualStim_contrastLeft.npy': 'contrast_left',\n",
    "                'trials.visualStim_contrastRight.npy': 'contrast_right',\n",
    "                'trials.visualStim_times.npy': 'stimulus_times',\n",
    "            }\n",
    "\n",
    "            # Extract and load each file\n",
    "            for file_name, attr_name in file_attr_map.items():\n",
    "                if file_name not in trial_files:\n",
    "                    print(f\"Warning: {file_name} not found in tar archive\")\n",
    "                    continue\n",
    "\n",
    "                # try:\n",
    "                #     # Extract file to memory and load with numpy\n",
    "                #     member = tar.extractfile(file_name)\n",
    "                #     if member is None:\n",
    "                #         raise ValueError(f\"Could not extract {file_name}\")\n",
    "\n",
    "                array_data = npy_loader(tar,file_name)\n",
    "                setattr(data, attr_name, array_data)\n",
    "\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "@dataclass\n",
    "class Spikes:\n",
    "    amps: Optional[np.ndarray] = None\n",
    "    clusters: Optional[np.ndarray] = None\n",
    "    depths: Optional[np.ndarray] = None\n",
    "    times: Optional[np.ndarray] = None\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the Trials data to a pandas DataFrame.\n",
    "        For multi-dimensional arrays, only the first dimension is used as the index,\n",
    "        and the remaining dimensions are stored as array objects in the cells.\n",
    "        \"\"\"\n",
    "        data_dict = {}\n",
    "        base_length = None\n",
    "\n",
    "        # Process each attribute\n",
    "        for attr_name, value in self.__dict__.items():\n",
    "            if value is not None:\n",
    "                if len(value.shape) == 1:\n",
    "                    # 1D arrays can be directly added\n",
    "                    data_dict[attr_name] = value\n",
    "                    if base_length is None:\n",
    "                        base_length = len(value)\n",
    "                else:\n",
    "                    # For multi-dimensional arrays, store them as objects\n",
    "                    # Each row will contain a slice of the array\n",
    "                    data_dict[attr_name] = [value[i] for i in range(value.shape[0])]\n",
    "                    if base_length is None:\n",
    "                        base_length = value.shape[0]\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def from_tar(cls, tar_path: str | Path) -> 'Spikes':\n",
    "        \"\"\"\n",
    "        Load cluster data from a tar file containing numpy arrays.\n",
    "\n",
    "        Args:\n",
    "            tar_path: Path to the tar file containing cluster data\n",
    "\n",
    "        Returns:\n",
    "            ClusterData instance with loaded arrays\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If tar file doesn't exist\n",
    "            ValueError: If expected cluster files are missing\n",
    "        \"\"\"\n",
    "        # if not os.path.exists(tar_path):\n",
    "        #     raise FileNotFoundError(f\"Tar file not found: {tar_path}\")\n",
    "\n",
    "        data = cls()\n",
    "\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            trial_files = [name for name in tar.getnames() if name.startswith('spikes')]\n",
    "\n",
    "            # Mapping between file names and dataclass attributes\n",
    "            file_attr_map = {\n",
    "                'spikes.amps.npy': 'amps',\n",
    "                'spikes.clusters.npy': 'clusters',\n",
    "                'spikes.depths.npy': 'depths',\n",
    "                'spikes.times.npy': 'times',\n",
    "            }\n",
    "\n",
    "            # Extract and load each file\n",
    "            for file_name, attr_name in file_attr_map.items():\n",
    "                if file_name not in trial_files:\n",
    "                    print(f\"Warning: {file_name} not found in tar archive\")\n",
    "                    continue\n",
    "\n",
    "                # try:\n",
    "                #     # Extract file to memory and load with numpy\n",
    "                #     member = tar.extractfile(file_name)\n",
    "                #     if member is None:\n",
    "                #         raise ValueError(f\"Could not extract {file_name}\")\n",
    "\n",
    "                array_data = npy_loader(tar,file_name)\n",
    "                setattr(data, attr_name, array_data)\n",
    "\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "\n",
    "        return data"
   ],
   "id": "ffa1c95892706ab8",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:09:35.624034Z",
     "start_time": "2025-02-01T17:09:35.472306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alldata_tar_path = os.path.join(os.getcwd(),data_directory,test_LFP + r\".tar\")\n",
    "with tarfile.open(alldata_tar_path, 'r') as tar:\n",
    "    print(type(tar))\n",
    "    # print(tar.getnames())\n",
    "\n",
    "    clusters = [name for name in tar.getnames() if name.startswith('clusters')]\n",
    "    spikes = [name for name in tar.getnames() if name.startswith('spikes')]\n",
    "    trials = [name for name in tar.getnames() if name.startswith('trials')]\n",
    "    print(clusters)\n",
    "    print(spikes)\n",
    "    print(trials)\n",
    "\n",
    "    for spike in spikes:\n",
    "        print(npy_loader(tar,spike).shape)\n",
    "\n",
    "    for cluster in clusters:\n",
    "        print(npy_loader(tar,cluster).shape)\n",
    "\n",
    "    for trial in trials:\n",
    "        print(npy_loader(tar,trial).shape)\n",
    "\n",
    "cluster_data = Clusters.from_tar(alldata_tar_path)\n",
    "trials = Trials.from_tar(alldata_tar_path)"
   ],
   "id": "6b49f04c7b88a7d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tarfile.TarFile'>\n",
      "['clusters.depths.npy', 'clusters.originalIDs.npy', 'clusters.peakChannel.npy', 'clusters.probes.npy', 'clusters.templateWaveformChans.npy', 'clusters.templateWaveforms.npy', 'clusters.waveformDuration.npy', 'clusters._phy_annotation.npy']\n",
      "['spikes.amps.npy', 'spikes.clusters.npy', 'spikes.depths.npy', 'spikes.times.npy']\n",
      "['trials.feedbackType.npy', 'trials.feedback_times.npy', 'trials.goCue_times.npy', 'trials.included.npy', 'trials.intervals.npy', 'trials.repNum.npy', 'trials.response_choice.npy', 'trials.response_times.npy', 'trials.visualStim_contrastLeft.npy', 'trials.visualStim_contrastRight.npy', 'trials.visualStim_times.npy']\n",
      "(10379618, 1)\n",
      "(10379618, 1)\n",
      "(10379618, 1)\n",
      "(10379618, 1)\n",
      "(1146, 1)\n",
      "(1146, 1)\n",
      "(1146, 1)\n",
      "(1146, 1)\n",
      "(1146, 50)\n",
      "(1146, 82, 50)\n",
      "(1146, 1)\n",
      "(1146, 1)\n",
      "(251, 1)\n",
      "(251, 1)\n",
      "(251, 1)\n",
      "(251, 1)\n",
      "(251, 2)\n",
      "(251, 1)\n",
      "(251, 1)\n",
      "(251, 1)\n",
      "(251, 1)\n",
      "(251, 1)\n",
      "(251, 1)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:33:55.691793Z",
     "start_time": "2025-02-01T15:33:55.683186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cluster_df = cluster_data.to_dataframe().query('phy_annotation != 1.0')\n",
    "cluster_df.phy_annotation.value_counts()"
   ],
   "id": "57d6e20dc1cb3a9e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phy_annotation\n",
       "[2.0]    1069\n",
       "[3.0]       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:00.889325Z",
     "start_time": "2025-02-01T15:34:00.794856Z"
    }
   },
   "cell_type": "code",
   "source": "cluster_df.head()",
   "id": "c134ac20fe4948a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 depths original_ids peak_channel probes  \\\n",
       "0  [2094.0924379360854]          [1]      [205.0]  [0.0]   \n",
       "1  [3174.3952154674303]          [2]      [310.0]  [0.0]   \n",
       "2  [171.90866042710923]          [3]       [18.0]  [0.0]   \n",
       "3  [482.96850438792995]          [4]       [49.0]  [0.0]   \n",
       "5  [2178.9536964067097]          [6]      [212.0]  [0.0]   \n",
       "\n",
       "                             template_waveform_chans  \\\n",
       "0  [204.0, 203.0, 202.0, 201.0, 206.0, 205.0, 199...   \n",
       "1  [309.0, 307.0, 311.0, 308.0, 313.0, 305.0, 304...   \n",
       "2  [17.0, 15.0, 13.0, 19.0, 16.0, 21.0, 12.0, 11....   \n",
       "3  [48.0, 46.0, 44.0, 50.0, 47.0, 43.0, 42.0, 45....   \n",
       "5  [211.0, 209.0, 214.0, 210.0, 212.0, 213.0, 207...   \n",
       "\n",
       "                                  template_waveforms waveform_duration  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            [28.0]   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            [17.0]   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            [23.0]   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            [18.0]   \n",
       "5  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...            [25.0]   \n",
       "\n",
       "  phy_annotation  \n",
       "0          [2.0]  \n",
       "1          [2.0]  \n",
       "2          [2.0]  \n",
       "3          [2.0]  \n",
       "5          [2.0]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depths</th>\n",
       "      <th>original_ids</th>\n",
       "      <th>peak_channel</th>\n",
       "      <th>probes</th>\n",
       "      <th>template_waveform_chans</th>\n",
       "      <th>template_waveforms</th>\n",
       "      <th>waveform_duration</th>\n",
       "      <th>phy_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2094.0924379360854]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[205.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[204.0, 203.0, 202.0, 201.0, 206.0, 205.0, 199...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[28.0]</td>\n",
       "      <td>[2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[3174.3952154674303]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[310.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[309.0, 307.0, 311.0, 308.0, 313.0, 305.0, 304...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[17.0]</td>\n",
       "      <td>[2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[171.90866042710923]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[18.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[17.0, 15.0, 13.0, 19.0, 16.0, 21.0, 12.0, 11....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[23.0]</td>\n",
       "      <td>[2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[482.96850438792995]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[49.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[48.0, 46.0, 44.0, 50.0, 47.0, 43.0, 42.0, 45....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[18.0]</td>\n",
       "      <td>[2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2178.9536964067097]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[212.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[211.0, 209.0, 214.0, 210.0, 212.0, 213.0, 207...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[25.0]</td>\n",
       "      <td>[2.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:34:17.382464Z",
     "start_time": "2025-02-01T15:34:17.379231Z"
    }
   },
   "cell_type": "code",
   "source": "cluster_df.template_waveforms.iloc[0].T.shape",
   "id": "65bf6559ec93bfa3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 82)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T15:37:23.246421Z",
     "start_time": "2025-02-01T15:37:23.242447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trial_df = trials.to_dataframe()\n",
    "trial_df.head()"
   ],
   "id": "b7aa9bea6dbd36cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 11)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:10:08.888768Z",
     "start_time": "2025-02-01T17:10:00.733772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spike_data = Spikes.from_tar(alldata_tar_path)\n",
    "spike_df = spike_data.to_dataframe()\n",
    "spike_df.head()"
   ],
   "id": "a26198014701546b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   amps clusters       depths                    times\n",
       "0   [348.2527631004607]     [73]   [2893.285]  [0.0034333333333333334]\n",
       "1  [172.98296191495376]    [176]  [2327.7686]   [0.007033333333333333]\n",
       "2   [351.8927727973601]    [254]  [2219.6008]   [0.007566666666666667]\n",
       "3   [495.4610743675204]     [21]  [2159.3933]   [0.008166666666666666]\n",
       "4   [92.05229598127468]     [69]   [3095.128]                 [0.0087]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amps</th>\n",
       "      <th>clusters</th>\n",
       "      <th>depths</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[348.2527631004607]</td>\n",
       "      <td>[73]</td>\n",
       "      <td>[2893.285]</td>\n",
       "      <td>[0.0034333333333333334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[172.98296191495376]</td>\n",
       "      <td>[176]</td>\n",
       "      <td>[2327.7686]</td>\n",
       "      <td>[0.007033333333333333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[351.8927727973601]</td>\n",
       "      <td>[254]</td>\n",
       "      <td>[2219.6008]</td>\n",
       "      <td>[0.007566666666666667]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[495.4610743675204]</td>\n",
       "      <td>[21]</td>\n",
       "      <td>[2159.3933]</td>\n",
       "      <td>[0.008166666666666666]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[92.05229598127468]</td>\n",
       "      <td>[69]</td>\n",
       "      <td>[3095.128]</td>\n",
       "      <td>[0.0087]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T17:10:19.146093Z",
     "start_time": "2025-02-01T17:10:19.143558Z"
    }
   },
   "cell_type": "code",
   "source": "print(spike_df.shape)",
   "id": "4784f975dd7df675",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10379618, 4)\n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
