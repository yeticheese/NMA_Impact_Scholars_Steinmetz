{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:14:59.055211Z",
     "start_time": "2025-02-08T18:14:57.279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "from src.file_ops import npy_loader, get_probe_signals\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "id": "c7100dfc0e89cc59",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:14:59.062087Z",
     "start_time": "2025-02-08T18:14:59.055211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the current working directory\n",
    "cwd = os.chdir(r\"C:\\Python Work Directory\\NMA_Impact_Scholars_Steinmetz\")\n",
    "\n",
    "# @title Data retrieval\n",
    "data_directory = r'data\\spikeAndBehavioralData'\n",
    "\n",
    "session_label_string = \"Cori_2016-12-17\"\n",
    "\n",
    "session_label = session_label_string.split(\"_\")\n",
    "print(session_label)\n",
    "\n",
    "# test_dataset\n",
    "test_LFP = r\"Cori_2016-12-17\""
   ],
   "id": "42096b6f6939cf00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cori', '2016-12-17']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:14:59.375840Z",
     "start_time": "2025-02-08T18:14:59.370392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "walker = os.walk(os.path.join(os.getcwd(),data_directory))\n",
    "for root, dirs, files in walker:\n",
    "    print(root)\n",
    "    print(dirs)\n",
    "    for file in files:\n",
    "        print(file)\n"
   ],
   "id": "2bf149e36eb2efa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Python Work Directory\\NMA_Impact_Scholars_Steinmetz\\data\\spikeAndBehavioralData\n",
      "[]\n",
      "Cori_2016-12-14.tar\n",
      "Cori_2016-12-17.tar\n",
      "Cori_2016-12-18.tar\n",
      "Forssmann_2017-11-01.tar\n",
      "Forssmann_2017-11-02.tar\n",
      "Forssmann_2017-11-04.tar\n",
      "Forssmann_2017-11-05.tar\n",
      "Hench_2017-06-15.tar\n",
      "Hench_2017-06-16.tar\n",
      "Hench_2017-06-17.tar\n",
      "Hench_2017-06-18.tar\n",
      "Lederberg_2017-12-05.tar\n",
      "Lederberg_2017-12-06.tar\n",
      "Lederberg_2017-12-07.tar\n",
      "Lederberg_2017-12-08.tar\n",
      "Lederberg_2017-12-09.tar\n",
      "Lederberg_2017-12-10.tar\n",
      "Lederberg_2017-12-11.tar\n",
      "Moniz_2017-05-15.tar\n",
      "Moniz_2017-05-16.tar\n",
      "Moniz_2017-05-18.tar\n",
      "Muller_2017-01-07.tar\n",
      "Muller_2017-01-08.tar\n",
      "Muller_2017-01-09.tar\n",
      "Radnitz_2017-01-08.tar\n",
      "Radnitz_2017-01-09.tar\n",
      "Radnitz_2017-01-10.tar\n",
      "Radnitz_2017-01-11.tar\n",
      "Radnitz_2017-01-12.tar\n",
      "Richards_2017-10-29.tar\n",
      "Richards_2017-10-30.tar\n",
      "Richards_2017-10-31.tar\n",
      "Richards_2017-11-01.tar\n",
      "Richards_2017-11-02.tar\n",
      "Tatum_2017-12-06.tar\n",
      "Tatum_2017-12-07.tar\n",
      "Tatum_2017-12-08.tar\n",
      "Tatum_2017-12-09.tar\n",
      "Theiler_2017-10-11.tar\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:14:59.389448Z",
     "start_time": "2025-02-08T18:14:59.379178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def extract_spikes_data(filename):\n",
    "#     with tarfile.open(filename) as tar:\n",
    "#         spikes = [name for name in tar.getnames() if name.startswith('spikes')]"
   ],
   "id": "4bf1a58f7ad4bd64",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:14:59.425546Z",
     "start_time": "2025-02-08T18:14:59.404341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Clusters:\n",
    "    depths: Optional[np.ndarray] = None\n",
    "    original_ids: Optional[np.ndarray] = None\n",
    "    site: Optional[np.ndarray] = None\n",
    "    probes: Optional[np.ndarray] = None\n",
    "    template_waveform_chans: Optional[np.ndarray] = None\n",
    "    template_waveforms: Optional[np.ndarray] = None\n",
    "    waveform_duration: Optional[np.ndarray] = None\n",
    "    phy_annotation: Optional[np.ndarray] = None\n",
    "\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the cluster data to a pandas DataFrame.\n",
    "        For multi-dimensional arrays, only the first dimension is used as the index,\n",
    "        and the remaining dimensions are stored as array objects in the cells.\n",
    "        \"\"\"\n",
    "        data_dict = {}\n",
    "        base_length = None\n",
    "\n",
    "        # Process each attribute\n",
    "        for attr_name, value in self.__dict__.items():\n",
    "            if value is not None:\n",
    "                if len(value.shape) == 1:\n",
    "                    # 1D arrays can be directly added\n",
    "                    data_dict[attr_name] = value\n",
    "                    if base_length is None:\n",
    "                        base_length = len(value)\n",
    "                else:\n",
    "                    # For multi-dimensional arrays, store them as objects\n",
    "                    # Each row will contain a slice of the array\n",
    "                    data_dict[attr_name] = [value[i] for i in range(value.shape[0])]\n",
    "                    if base_length is None:\n",
    "                        base_length = value.shape[0]\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def from_tar(cls, tar_path: str | Path) -> 'Clusters':\n",
    "        \"\"\"\n",
    "        Load cluster data from a tar file containing numpy arrays.\n",
    "\n",
    "        Args:\n",
    "            tar_path: Path to the tar file containing cluster data\n",
    "\n",
    "        Returns:\n",
    "            ClusterData instance with loaded arrays\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If tar file doesn't exist\n",
    "            ValueError: If expected cluster files are missing\n",
    "        \"\"\"\n",
    "        # if not os.path.exists(tar_path):\n",
    "        #     raise FileNotFoundError(f\"Tar file not found: {tar_path}\")\n",
    "\n",
    "        data = cls()\n",
    "\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            cluster_files = [name for name in tar.getnames() if name.startswith('clusters')]\n",
    "\n",
    "            # Mapping between file names and dataclass attributes\n",
    "            file_attr_map = {\n",
    "                'clusters.depths.npy': 'depths',\n",
    "                'clusters.originalIDs.npy': 'original_ids',\n",
    "                'clusters.peakChannel.npy': 'site',\n",
    "                'clusters.probes.npy': 'probes',\n",
    "                'clusters.templateWaveformChans.npy': 'template_waveform_chans',\n",
    "                'clusters.templateWaveforms.npy': 'template_waveforms',\n",
    "                'clusters.waveformDuration.npy': 'waveform_duration',\n",
    "                'clusters._phy_annotation.npy': 'phy_annotation'\n",
    "            }\n",
    "\n",
    "            # Extract and load each file\n",
    "            for file_name, attr_name in file_attr_map.items():\n",
    "                if file_name not in cluster_files:\n",
    "                    print(f\"Warning: {file_name} not found in tar archive\")\n",
    "                    continue\n",
    "\n",
    "                # try:\n",
    "                #     # Extract file to memory and load with numpy\n",
    "                #     member = tar.extractfile(file_name)\n",
    "                #     if member is None:\n",
    "                #         raise ValueError(f\"Could not extract {file_name}\")\n",
    "\n",
    "                array_data = np.squeeze(npy_loader(tar,file_name))\n",
    "                setattr(data, attr_name, array_data)\n",
    "\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "@dataclass\n",
    "class Trials:\n",
    "    feedback_type: Optional[np.ndarray] = None\n",
    "    feedback_times: Optional[np.ndarray] = None\n",
    "    gocue_times: Optional[np.ndarray] = None\n",
    "    included: Optional[np.ndarray] = None\n",
    "    intervals: Optional[np.ndarray] = None\n",
    "    repNum: Optional[np.ndarray] = None\n",
    "    response_choice: Optional[np.ndarray] = None\n",
    "    response_times: Optional[np.ndarray] = None\n",
    "    contrast_left: Optional[np.ndarray] = None\n",
    "    constra_right: Optional[np.ndarray] = None\n",
    "    stimulus_times: Optional[np.ndarray] = None\n",
    "\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the Trials data to a pandas DataFrame.\n",
    "        For multi-dimensional arrays, only the first dimension is used as the index,\n",
    "        and the remaining dimensions are stored as array objects in the cells.\n",
    "        \"\"\"\n",
    "        data_dict = {}\n",
    "        base_length = None\n",
    "\n",
    "        # Process each attribute\n",
    "        for attr_name, value in self.__dict__.items():\n",
    "            if value is not None:\n",
    "                if len(value.shape) == 1:\n",
    "                    # 1D arrays can be directly added\n",
    "                    data_dict[attr_name] = value\n",
    "                    if base_length is None:\n",
    "                        base_length = len(value)\n",
    "                else:\n",
    "                    # For multi-dimensional arrays, store them as objects\n",
    "                    # Each row will contain a slice of the array\n",
    "                    data_dict[attr_name] = [value[i] for i in range(value.shape[0])]\n",
    "                    if base_length is None:\n",
    "                        base_length = value.shape[0]\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def from_tar(cls, tar_path: str | Path) -> 'Trials':\n",
    "        \"\"\"\n",
    "        Load cluster data from a tar file containing numpy arrays.\n",
    "\n",
    "        Args:\n",
    "            tar_path: Path to the tar file containing cluster data\n",
    "\n",
    "        Returns:\n",
    "            ClusterData instance with loaded arrays\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If tar file doesn't exist\n",
    "            ValueError: If expected cluster files are missing\n",
    "        \"\"\"\n",
    "        # if not os.path.exists(tar_path):\n",
    "        #     raise FileNotFoundError(f\"Tar file not found: {tar_path}\")\n",
    "\n",
    "        data = cls()\n",
    "\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            trial_files = [name for name in tar.getnames() if name.startswith('trials')]\n",
    "\n",
    "            # Mapping between file names and dataclass attributes\n",
    "            file_attr_map = {\n",
    "                'trials.feedbackType.npy': 'feedback_type',\n",
    "                'trials.feedback_times.npy': 'feedback_times',\n",
    "                'trials.goCue_times.npy': 'gocue_times',\n",
    "                'trials.included.npy': 'included',\n",
    "                'trials.intervals.npy': 'intervals',\n",
    "                'trials.repNum.npy': 'repNum',\n",
    "                'trials.response_choice.npy': 'response_choice',\n",
    "                'trials.response_times.npy': 'response_times',\n",
    "                'trials.visualStim_contrastLeft.npy': 'contrast_left',\n",
    "                'trials.visualStim_contrastRight.npy': 'contrast_right',\n",
    "                'trials.visualStim_times.npy': 'stimulus_times',\n",
    "            }\n",
    "\n",
    "            # Extract and load each file\n",
    "            for file_name, attr_name in file_attr_map.items():\n",
    "                if file_name not in trial_files:\n",
    "                    print(f\"Warning: {file_name} not found in tar archive\")\n",
    "                    continue\n",
    "\n",
    "                # try:\n",
    "                #     # Extract file to memory and load with numpy\n",
    "                #     member = tar.extractfile(file_name)\n",
    "                #     if member is None:\n",
    "                #         raise ValueError(f\"Could not extract {file_name}\")\n",
    "\n",
    "                array_data = np.squeeze(npy_loader(tar,file_name))\n",
    "                setattr(data, attr_name, array_data)\n",
    "\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "@dataclass\n",
    "class Spikes:\n",
    "    amps: Optional[np.ndarray] = None\n",
    "    clusters: Optional[np.ndarray] = None\n",
    "    depths: Optional[np.ndarray] = None\n",
    "    times: Optional[np.ndarray] = None\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert the Trials data to a pandas DataFrame.\n",
    "        For multi-dimensional arrays, only the first dimension is used as the index,\n",
    "        and the remaining dimensions are stored as array objects in the cells.\n",
    "        \"\"\"\n",
    "        data_dict = {}\n",
    "        base_length = None\n",
    "\n",
    "        # Process each attribute\n",
    "        for attr_name, value in self.__dict__.items():\n",
    "            if value is not None:\n",
    "                if len(value.shape) == 1:\n",
    "                    # 1D arrays can be directly added\n",
    "                    data_dict[attr_name] = value\n",
    "                    if base_length is None:\n",
    "                        base_length = len(value)\n",
    "                else:\n",
    "                    # For multi-dimensional arrays, store them as objects\n",
    "                    # Each row will contain a slice of the array\n",
    "                    data_dict[attr_name] = [value[i] for i in range(value.shape[0])]\n",
    "                    if base_length is None:\n",
    "                        base_length = value.shape[0]\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        return df\n",
    "\n",
    "    @classmethod\n",
    "    def from_tar(cls, tar_path: str | Path) -> 'Spikes':\n",
    "        \"\"\"\n",
    "        Load cluster data from a tar file containing numpy arrays.\n",
    "\n",
    "        Args:\n",
    "            tar_path: Path to the tar file containing cluster data\n",
    "\n",
    "        Returns:\n",
    "            ClusterData instance with loaded arrays\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If tar file doesn't exist\n",
    "            ValueError: If expected cluster files are missing\n",
    "        \"\"\"\n",
    "        # if not os.path.exists(tar_path):\n",
    "        #     raise FileNotFoundError(f\"Tar file not found: {tar_path}\")\n",
    "\n",
    "        data = cls()\n",
    "\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            trial_files = [name for name in tar.getnames() if name.startswith('spikes')]\n",
    "\n",
    "            # Mapping between file names and dataclass attributes\n",
    "            file_attr_map = {\n",
    "                'spikes.amps.npy': 'amps',\n",
    "                'spikes.clusters.npy': 'clusters',\n",
    "                'spikes.depths.npy': 'depths',\n",
    "                'spikes.times.npy': 'times',\n",
    "            }\n",
    "\n",
    "            # Extract and load each file\n",
    "            for file_name, attr_name in file_attr_map.items():\n",
    "                if file_name not in trial_files:\n",
    "                    print(f\"Warning: {file_name} not found in tar archive\")\n",
    "                    continue\n",
    "\n",
    "                # try:\n",
    "                #     # Extract file to memory and load with numpy\n",
    "                #     member = tar.extractfile(file_name)\n",
    "                #     if member is None:\n",
    "                #         raise ValueError(f\"Could not extract {file_name}\")\n",
    "\n",
    "                array_data = np.squeeze(npy_loader(tar,file_name))\n",
    "                setattr(data, attr_name, array_data)\n",
    "\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Error loading {file_name}: {str(e)}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "@dataclass\n",
    "class BrainLocation:\n",
    "    \"\"\"Dataclass for brain location information from channels.brainLocation.tsv\"\"\"\n",
    "    ccf_ap: np.ndarray  # AP position in CCF [µm]\n",
    "    ccf_dv: np.ndarray  # DV position in CCF [µm]\n",
    "    ccf_lr: np.ndarray  # LR position in CCF [µm]\n",
    "    allen_ontology: np.ndarray  # Brain region acronyms\n",
    "\n",
    "    @classmethod\n",
    "    def from_tsv(cls, tsv_file) -> 'BrainLocation':\n",
    "        \"\"\"Load brain location data from a TSV file or file-like object\"\"\"\n",
    "        df = pd.read_csv(tsv_file, sep='\\t')\n",
    "        return cls(\n",
    "            ccf_ap=df['ccf_ap'].to_numpy(),\n",
    "            ccf_dv=df['ccf_dv'].to_numpy(),\n",
    "            ccf_lr=df['ccf_lr'].to_numpy(),\n",
    "            allen_ontology=df['allen_ontology'].to_numpy()\n",
    "        )\n",
    "\n",
    "@dataclass\n",
    "class Channels:\n",
    "    \"\"\"Main dataclass for channel-related data\"\"\"\n",
    "    brain_location: Optional[BrainLocation] = None\n",
    "    probes: Optional[np.ndarray] = None  # [integer] (nChannels)\n",
    "    raw_row: Optional[np.ndarray] = None  # [integer] (nChannels)\n",
    "    site: Optional[np.ndarray] = None  # [integer] (nChannels)\n",
    "    site_positions: Optional[np.ndarray] = None  # [µm] (nChannels, 2)\n",
    "\n",
    "    @classmethod\n",
    "    def from_tar(cls, tar_path: str | Path) -> 'ChannelData':\n",
    "        \"\"\"\n",
    "        Load channel data from a tar file containing the channel-related files.\n",
    "\n",
    "        Args:\n",
    "            tar_path: Path to the tar file containing channel data\n",
    "\n",
    "        Returns:\n",
    "            ChannelData instance with loaded arrays\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If tar file doesn't exist\n",
    "            ValueError: If expected channel files are missing\n",
    "        \"\"\"\n",
    "        if not os.path.exists(tar_path):\n",
    "            raise FileNotFoundError(f\"Tar file not found: {tar_path}\")\n",
    "\n",
    "        data = cls()\n",
    "\n",
    "        with tarfile.open(tar_path, 'r') as tar:\n",
    "            channel_files = [name for name in tar.getnames() if name.startswith('channels')]\n",
    "\n",
    "            # Load brain location TSV file\n",
    "            if 'channels.brainLocation.tsv' in channel_files:\n",
    "                member = tar.extractfile('channels.brainLocation.tsv')\n",
    "                if member is not None:\n",
    "                    data.brain_location = BrainLocation.from_tsv(member)\n",
    "\n",
    "            # Mapping between NPY files and dataclass attributes\n",
    "            npy_file_map = {\n",
    "                'channels.probe.npy': 'probes',\n",
    "                'channels.rawRow.npy': 'raw_row',\n",
    "                'channels.site.npy': 'site',\n",
    "                'channels.sitePositions.npy': 'site_positions'\n",
    "            }\n",
    "\n",
    "            # Load NPY files\n",
    "            for file_name, attr_name in npy_file_map.items():\n",
    "                if file_name in channel_files:\n",
    "                    try:\n",
    "                        member = tar.extractfile(file_name)\n",
    "                        if member is None:\n",
    "                            raise ValueError(f\"Could not extract {file_name}\")\n",
    "\n",
    "                        array_data = np.squeeze(npy_loader(tar,file_name))\n",
    "                        setattr(data, attr_name, array_data)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {file_name}: {str(e)}\")\n",
    "                else:\n",
    "                    print(f\"Warning: {file_name} not found in tar archive\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    def to_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Convert channel data to a pandas DataFrame.\n",
    "        For multi-dimensional arrays (like site_positions), stores them as array objects.\n",
    "        \"\"\"\n",
    "        data_dict = {}\n",
    "\n",
    "        # Add brain location data if available\n",
    "        if self.brain_location is not None:\n",
    "            data_dict.update({\n",
    "                'ccf_ap': self.brain_location.ccf_ap,\n",
    "                'ccf_dv': self.brain_location.ccf_dv,\n",
    "                'ccf_lr': self.brain_location.ccf_lr,\n",
    "                'allen_ontology': self.brain_location.allen_ontology\n",
    "            })\n",
    "\n",
    "        # Add other channel data\n",
    "        if self.probes is not None:\n",
    "            data_dict['probes'] = self.probes\n",
    "        if self.raw_row is not None:\n",
    "            data_dict['raw_row'] = self.raw_row\n",
    "        if self.site is not None:\n",
    "            data_dict['site'] = self.site\n",
    "        if self.site_positions is not None:\n",
    "            # Store 2D site positions as array objects\n",
    "            data_dict['site_positions'] = [pos for pos in self.site_positions]\n",
    "\n",
    "        return pd.DataFrame(data_dict)"
   ],
   "id": "ffa1c95892706ab8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:00.354232Z",
     "start_time": "2025-02-08T18:14:59.429263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alldata_tar_path = os.path.join(os.getcwd(),data_directory,test_LFP + r\".tar\")\n",
    "with tarfile.open(alldata_tar_path, 'r') as tar:\n",
    "    print(type(tar))\n",
    "    # print(tar.getnames())\n",
    "\n",
    "    clusters = [name for name in tar.getnames() if name.startswith('clusters')]\n",
    "    spikes = [name for name in tar.getnames() if name.startswith('spikes')]\n",
    "    trials = [name for name in tar.getnames() if name.startswith('trials')]\n",
    "    print(clusters)\n",
    "    print(spikes)\n",
    "    print(trials)\n",
    "    wheel = [name for name in tar.getnames() if name.startswith('wheel.position')]\n",
    "    print(wheel)\n",
    "    wheel_pos = npy_loader(tar,wheel[0])\n",
    "    # for spike in spikes:\n",
    "    #     print(npy_loader(tar,spike).shape)\n",
    "    #\n",
    "    # for cluster in clusters:\n",
    "    #     print(npy_loader(tar,cluster).shape)\n",
    "    #\n",
    "    # for trial in trials:\n",
    "    #     print(npy_loader(tar,trial).shape)\n",
    "\n",
    "cluster_data = Clusters.from_tar(alldata_tar_path)\n",
    "trials = Trials.from_tar(alldata_tar_path)\n",
    "spike_data = Spikes.from_tar(alldata_tar_path)\n",
    "channel_data = Channels.from_tar(alldata_tar_path)"
   ],
   "id": "6b49f04c7b88a7d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tarfile.TarFile'>\n",
      "['clusters.depths.npy', 'clusters.originalIDs.npy', 'clusters.peakChannel.npy', 'clusters.probes.npy', 'clusters.templateWaveformChans.npy', 'clusters.templateWaveforms.npy', 'clusters.waveformDuration.npy', 'clusters._phy_annotation.npy']\n",
      "['spikes.amps.npy', 'spikes.clusters.npy', 'spikes.depths.npy', 'spikes.times.npy']\n",
      "['trials.feedbackType.npy', 'trials.feedback_times.npy', 'trials.goCue_times.npy', 'trials.included.npy', 'trials.intervals.npy', 'trials.repNum.npy', 'trials.response_choice.npy', 'trials.response_times.npy', 'trials.visualStim_contrastLeft.npy', 'trials.visualStim_contrastRight.npy', 'trials.visualStim_times.npy']\n",
      "['wheel.position.npy']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:00.384642Z",
     "start_time": "2025-02-08T18:15:00.373803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cluster_df = cluster_data.to_dataframe().query('phy_annotation != 1.0')\n",
    "cluster_df.phy_annotation.value_counts()"
   ],
   "id": "57d6e20dc1cb3a9e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phy_annotation\n",
       "2.0    1069\n",
       "3.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:00.521928Z",
     "start_time": "2025-02-08T18:15:00.431737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cluster_df[['mouse_name', 'date_exp']] = session_label\n",
    "cluster_df.head()"
   ],
   "id": "b7da85af3f299077",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        depths  original_ids   site  probes  \\\n",
       "0  2094.092438             1  205.0     0.0   \n",
       "1  3174.395215             2  310.0     0.0   \n",
       "2   171.908660             3   18.0     0.0   \n",
       "3   482.968504             4   49.0     0.0   \n",
       "5  2178.953696             6  212.0     0.0   \n",
       "\n",
       "                             template_waveform_chans  \\\n",
       "0  [204.0, 203.0, 202.0, 201.0, 206.0, 205.0, 199...   \n",
       "1  [309.0, 307.0, 311.0, 308.0, 313.0, 305.0, 304...   \n",
       "2  [17.0, 15.0, 13.0, 19.0, 16.0, 21.0, 12.0, 11....   \n",
       "3  [48.0, 46.0, 44.0, 50.0, 47.0, 43.0, 42.0, 45....   \n",
       "5  [211.0, 209.0, 214.0, 210.0, 212.0, 213.0, 207...   \n",
       "\n",
       "                                  template_waveforms  waveform_duration  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               28.0   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               17.0   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               23.0   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               18.0   \n",
       "5  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               25.0   \n",
       "\n",
       "   phy_annotation mouse_name    date_exp  \n",
       "0             2.0       Cori  2016-12-17  \n",
       "1             2.0       Cori  2016-12-17  \n",
       "2             2.0       Cori  2016-12-17  \n",
       "3             2.0       Cori  2016-12-17  \n",
       "5             2.0       Cori  2016-12-17  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depths</th>\n",
       "      <th>original_ids</th>\n",
       "      <th>site</th>\n",
       "      <th>probes</th>\n",
       "      <th>template_waveform_chans</th>\n",
       "      <th>template_waveforms</th>\n",
       "      <th>waveform_duration</th>\n",
       "      <th>phy_annotation</th>\n",
       "      <th>mouse_name</th>\n",
       "      <th>date_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2094.092438</td>\n",
       "      <td>1</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[204.0, 203.0, 202.0, 201.0, 206.0, 205.0, 199...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3174.395215</td>\n",
       "      <td>2</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[309.0, 307.0, 311.0, 308.0, 313.0, 305.0, 304...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171.908660</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[17.0, 15.0, 13.0, 19.0, 16.0, 21.0, 12.0, 11....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>482.968504</td>\n",
       "      <td>4</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[48.0, 46.0, 44.0, 50.0, 47.0, 43.0, 42.0, 45....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2178.953696</td>\n",
       "      <td>6</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[211.0, 209.0, 214.0, 210.0, 212.0, 213.0, 207...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:00.549638Z",
     "start_time": "2025-02-08T18:15:00.540904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trial_df = trials.to_dataframe()\n",
    "trial_df[['mouse_name', 'date_exp']] = session_label\n",
    "trial_df.head()"
   ],
   "id": "b7aa9bea6dbd36cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   feedback_type  feedback_times  gocue_times  included  \\\n",
       "0           -1.0       89.889353    89.157155      True   \n",
       "1            1.0       95.213625    94.732019      True   \n",
       "2           -1.0       99.188694    98.442062      True   \n",
       "3            1.0      105.490943   105.092538      True   \n",
       "4           -1.0      114.204641   113.897839      True   \n",
       "\n",
       "                                  intervals  repNum  response_choice  \\\n",
       "0    [86.36687946509481, 90.87699428563835]     1.0             -1.0   \n",
       "1    [91.87486989590016, 96.17468648244063]     1.0              1.0   \n",
       "2   [97.17349547684987, 100.19191645857983]     1.0             -1.0   \n",
       "3  [101.18832980700331, 106.45731289113688]     1.0              1.0   \n",
       "4  [107.45484467064871, 115.20800277418245]     1.0              1.0   \n",
       "\n",
       "   response_times  contrast_left  stimulus_times  contrast_right mouse_name  \\\n",
       "0       89.889353           1.00       88.405147             1.0       Cori   \n",
       "1       95.172558           0.25       93.588406             0.0       Cori   \n",
       "2       99.188694           0.50       97.738054             0.5       Cori   \n",
       "3      105.455483           0.25      104.120927             0.0       Cori   \n",
       "4      114.204641           0.00      113.037030             0.0       Cori   \n",
       "\n",
       "     date_exp  \n",
       "0  2016-12-17  \n",
       "1  2016-12-17  \n",
       "2  2016-12-17  \n",
       "3  2016-12-17  \n",
       "4  2016-12-17  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback_type</th>\n",
       "      <th>feedback_times</th>\n",
       "      <th>gocue_times</th>\n",
       "      <th>included</th>\n",
       "      <th>intervals</th>\n",
       "      <th>repNum</th>\n",
       "      <th>response_choice</th>\n",
       "      <th>response_times</th>\n",
       "      <th>contrast_left</th>\n",
       "      <th>stimulus_times</th>\n",
       "      <th>contrast_right</th>\n",
       "      <th>mouse_name</th>\n",
       "      <th>date_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>89.889353</td>\n",
       "      <td>89.157155</td>\n",
       "      <td>True</td>\n",
       "      <td>[86.36687946509481, 90.87699428563835]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>89.889353</td>\n",
       "      <td>1.00</td>\n",
       "      <td>88.405147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>95.213625</td>\n",
       "      <td>94.732019</td>\n",
       "      <td>True</td>\n",
       "      <td>[91.87486989590016, 96.17468648244063]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.172558</td>\n",
       "      <td>0.25</td>\n",
       "      <td>93.588406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>99.188694</td>\n",
       "      <td>98.442062</td>\n",
       "      <td>True</td>\n",
       "      <td>[97.17349547684987, 100.19191645857983]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>99.188694</td>\n",
       "      <td>0.50</td>\n",
       "      <td>97.738054</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>105.490943</td>\n",
       "      <td>105.092538</td>\n",
       "      <td>True</td>\n",
       "      <td>[101.18832980700331, 106.45731289113688]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.455483</td>\n",
       "      <td>0.25</td>\n",
       "      <td>104.120927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>114.204641</td>\n",
       "      <td>113.897839</td>\n",
       "      <td>True</td>\n",
       "      <td>[107.45484467064871, 115.20800277418245]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.204641</td>\n",
       "      <td>0.00</td>\n",
       "      <td>113.037030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:00.736722Z",
     "start_time": "2025-02-08T18:15:00.614068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spike_df = spike_data.to_dataframe()\n",
    "spike_df[['mouse_name', 'date_exp']] = session_label\n",
    "spike_df.head()"
   ],
   "id": "a26198014701546b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         amps  clusters       depths     times mouse_name    date_exp\n",
       "0  348.252763        73  2893.284912  0.003433       Cori  2016-12-17\n",
       "1  172.982962       176  2327.768555  0.007033       Cori  2016-12-17\n",
       "2  351.892773       254  2219.600830  0.007567       Cori  2016-12-17\n",
       "3  495.461074        21  2159.393311  0.008167       Cori  2016-12-17\n",
       "4   92.052296        69  3095.127930  0.008700       Cori  2016-12-17"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amps</th>\n",
       "      <th>clusters</th>\n",
       "      <th>depths</th>\n",
       "      <th>times</th>\n",
       "      <th>mouse_name</th>\n",
       "      <th>date_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>348.252763</td>\n",
       "      <td>73</td>\n",
       "      <td>2893.284912</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.982962</td>\n",
       "      <td>176</td>\n",
       "      <td>2327.768555</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>351.892773</td>\n",
       "      <td>254</td>\n",
       "      <td>2219.600830</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>495.461074</td>\n",
       "      <td>21</td>\n",
       "      <td>2159.393311</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.052296</td>\n",
       "      <td>69</td>\n",
       "      <td>3095.127930</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:00.896997Z",
     "start_time": "2025-02-08T18:15:00.888663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "channel_df = channel_data.to_dataframe()\n",
    "channel_df[['mouse_name', 'date_exp']] = session_label\n",
    "channel_df[channel_df['allen_ontology'] == 'CA1'].head()"
   ],
   "id": "11d3556a32e5bb15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     ccf_ap  ccf_dv  ccf_lr allen_ontology  probes  raw_row  site  \\\n",
       "150  8101.1  3187.8  2232.1            CA1     0.0      154   154   \n",
       "151  8119.9  3187.8  2258.0            CA1     0.0      155   155   \n",
       "152  8115.4  3168.7  2241.5            CA1     0.0      156   156   \n",
       "153  8134.2  3168.7  2267.4            CA1     0.0      157   157   \n",
       "154  8110.8  3149.6  2225.1            CA1     0.0      158   158   \n",
       "\n",
       "     site_positions mouse_name    date_exp  \n",
       "150  [59.0, 1560.0]       Cori  2016-12-17  \n",
       "151  [27.0, 1560.0]       Cori  2016-12-17  \n",
       "152  [43.0, 1580.0]       Cori  2016-12-17  \n",
       "153  [11.0, 1580.0]       Cori  2016-12-17  \n",
       "154  [59.0, 1600.0]       Cori  2016-12-17  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccf_ap</th>\n",
       "      <th>ccf_dv</th>\n",
       "      <th>ccf_lr</th>\n",
       "      <th>allen_ontology</th>\n",
       "      <th>probes</th>\n",
       "      <th>raw_row</th>\n",
       "      <th>site</th>\n",
       "      <th>site_positions</th>\n",
       "      <th>mouse_name</th>\n",
       "      <th>date_exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>8101.1</td>\n",
       "      <td>3187.8</td>\n",
       "      <td>2232.1</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>[59.0, 1560.0]</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>8119.9</td>\n",
       "      <td>3187.8</td>\n",
       "      <td>2258.0</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>[27.0, 1560.0]</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>8115.4</td>\n",
       "      <td>3168.7</td>\n",
       "      <td>2241.5</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>[43.0, 1580.0]</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>8134.2</td>\n",
       "      <td>3168.7</td>\n",
       "      <td>2267.4</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>[11.0, 1580.0]</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>8110.8</td>\n",
       "      <td>3149.6</td>\n",
       "      <td>2225.1</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>[59.0, 1600.0]</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.110681Z",
     "start_time": "2025-02-08T18:15:01.099179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using merge\n",
    "cluster_df['allen_ontology'] = (\n",
    "    cluster_df.merge(\n",
    "        channel_df[['mouse_name', 'date_exp', 'probes', 'site', 'allen_ontology']],\n",
    "        left_on=['mouse_name', 'date_exp', 'probes', 'site'],\n",
    "        right_on=['mouse_name', 'date_exp', 'probes', 'site'],\n",
    "        how='left'\n",
    "    )['allen_ontology']\n",
    ")"
   ],
   "id": "2c2fa6bd2f041d8c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.286830Z",
     "start_time": "2025-02-08T18:15:01.186928Z"
    }
   },
   "cell_type": "code",
   "source": "cluster_df.head()",
   "id": "a484cd4d132d5edc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        depths  original_ids   site  probes  \\\n",
       "0  2094.092438             1  205.0     0.0   \n",
       "1  3174.395215             2  310.0     0.0   \n",
       "2   171.908660             3   18.0     0.0   \n",
       "3   482.968504             4   49.0     0.0   \n",
       "5  2178.953696             6  212.0     0.0   \n",
       "\n",
       "                             template_waveform_chans  \\\n",
       "0  [204.0, 203.0, 202.0, 201.0, 206.0, 205.0, 199...   \n",
       "1  [309.0, 307.0, 311.0, 308.0, 313.0, 305.0, 304...   \n",
       "2  [17.0, 15.0, 13.0, 19.0, 16.0, 21.0, 12.0, 11....   \n",
       "3  [48.0, 46.0, 44.0, 50.0, 47.0, 43.0, 42.0, 45....   \n",
       "5  [211.0, 209.0, 214.0, 210.0, 212.0, 213.0, 207...   \n",
       "\n",
       "                                  template_waveforms  waveform_duration  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               28.0   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               17.0   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               23.0   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               18.0   \n",
       "5  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               25.0   \n",
       "\n",
       "   phy_annotation mouse_name    date_exp allen_ontology  \n",
       "0             2.0       Cori  2016-12-17            CA1  \n",
       "1             2.0       Cori  2016-12-17           VISl  \n",
       "2             2.0       Cori  2016-12-17           root  \n",
       "3             2.0       Cori  2016-12-17           root  \n",
       "5             2.0       Cori  2016-12-17            CA1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depths</th>\n",
       "      <th>original_ids</th>\n",
       "      <th>site</th>\n",
       "      <th>probes</th>\n",
       "      <th>template_waveform_chans</th>\n",
       "      <th>template_waveforms</th>\n",
       "      <th>waveform_duration</th>\n",
       "      <th>phy_annotation</th>\n",
       "      <th>mouse_name</th>\n",
       "      <th>date_exp</th>\n",
       "      <th>allen_ontology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2094.092438</td>\n",
       "      <td>1</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[204.0, 203.0, 202.0, 201.0, 206.0, 205.0, 199...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>CA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3174.395215</td>\n",
       "      <td>2</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[309.0, 307.0, 311.0, 308.0, 313.0, 305.0, 304...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>VISl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171.908660</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[17.0, 15.0, 13.0, 19.0, 16.0, 21.0, 12.0, 11....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>482.968504</td>\n",
       "      <td>4</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[48.0, 46.0, 44.0, 50.0, 47.0, 43.0, 42.0, 45....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2178.953696</td>\n",
       "      <td>6</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[211.0, 209.0, 214.0, 210.0, 212.0, 213.0, 207...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>CA1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.321272Z",
     "start_time": "2025-02-08T18:15:01.317926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_peak_to_trough_duration(waveforms, sampling_rate=30000):\n",
    "    \"\"\"\n",
    "    Calculate the peak-to-trough duration of a waveform.\n",
    "\n",
    "    Parameters:\n",
    "    waveform (np.ndarray): Template waveform array\n",
    "    sampling_rate (int): Sampling rate in Hz, default 30000 for typical ephys\n",
    "\n",
    "    Returns:\n",
    "    float: Peak-to-trough duration in milliseconds\n",
    "    \"\"\"\n",
    "    # Find peak and trough indices\n",
    "    waveform = waveforms[:,0]\n",
    "\n",
    "    peak_idx = np.argmax(waveform)\n",
    "    trough_idx = np.argmin(waveform)\n",
    "\n",
    "    # Calculate time difference\n",
    "    time_diff_samples = abs(peak_idx - trough_idx)\n",
    "\n",
    "    # Convert to milliseconds\n",
    "    duration_ms = (time_diff_samples / sampling_rate) * 1000\n",
    "\n",
    "    return duration_ms"
   ],
   "id": "5e1896244aef428a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.356166Z",
     "start_time": "2025-02-08T18:15:01.350156Z"
    }
   },
   "cell_type": "code",
   "source": "cluster_df['peak_to_trough_duration'] = cluster_df['template_waveforms'].apply(calculate_peak_to_trough_duration)",
   "id": "2dd4bd180c8a6781",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:25.417896Z",
     "start_time": "2025-02-08T18:15:25.319442Z"
    }
   },
   "cell_type": "code",
   "source": "cluster_df.sort_values(['probes','original_ids']).head()",
   "id": "56f0211257b41d0c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        depths  original_ids   site  probes  \\\n",
       "0  2094.092438             1  205.0     0.0   \n",
       "1  3174.395215             2  310.0     0.0   \n",
       "2   171.908660             3   18.0     0.0   \n",
       "3   482.968504             4   49.0     0.0   \n",
       "5  2178.953696             6  212.0     0.0   \n",
       "\n",
       "                             template_waveform_chans  \\\n",
       "0  [204.0, 203.0, 202.0, 201.0, 206.0, 205.0, 199...   \n",
       "1  [309.0, 307.0, 311.0, 308.0, 313.0, 305.0, 304...   \n",
       "2  [17.0, 15.0, 13.0, 19.0, 16.0, 21.0, 12.0, 11....   \n",
       "3  [48.0, 46.0, 44.0, 50.0, 47.0, 43.0, 42.0, 45....   \n",
       "5  [211.0, 209.0, 214.0, 210.0, 212.0, 213.0, 207...   \n",
       "\n",
       "                                  template_waveforms  waveform_duration  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               28.0   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               17.0   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               23.0   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               18.0   \n",
       "5  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...               25.0   \n",
       "\n",
       "   phy_annotation mouse_name    date_exp allen_ontology  \\\n",
       "0             2.0       Cori  2016-12-17            CA1   \n",
       "1             2.0       Cori  2016-12-17           VISl   \n",
       "2             2.0       Cori  2016-12-17           root   \n",
       "3             2.0       Cori  2016-12-17           root   \n",
       "5             2.0       Cori  2016-12-17            CA1   \n",
       "\n",
       "   peak_to_trough_duration  \n",
       "0                 0.833333  \n",
       "1                 0.566667  \n",
       "2                 0.733333  \n",
       "3                 0.166667  \n",
       "5                 0.766667  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depths</th>\n",
       "      <th>original_ids</th>\n",
       "      <th>site</th>\n",
       "      <th>probes</th>\n",
       "      <th>template_waveform_chans</th>\n",
       "      <th>template_waveforms</th>\n",
       "      <th>waveform_duration</th>\n",
       "      <th>phy_annotation</th>\n",
       "      <th>mouse_name</th>\n",
       "      <th>date_exp</th>\n",
       "      <th>allen_ontology</th>\n",
       "      <th>peak_to_trough_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2094.092438</td>\n",
       "      <td>1</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[204.0, 203.0, 202.0, 201.0, 206.0, 205.0, 199...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3174.395215</td>\n",
       "      <td>2</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[309.0, 307.0, 311.0, 308.0, 313.0, 305.0, 304...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>VISl</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171.908660</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[17.0, 15.0, 13.0, 19.0, 16.0, 21.0, 12.0, 11....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>root</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>482.968504</td>\n",
       "      <td>4</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[48.0, 46.0, 44.0, 50.0, 47.0, 43.0, 42.0, 45....</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>root</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2178.953696</td>\n",
       "      <td>6</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[211.0, 209.0, 214.0, 210.0, 212.0, 213.0, 207...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cori</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.464196Z",
     "start_time": "2025-02-08T18:15:01.454677Z"
    }
   },
   "cell_type": "code",
   "source": "# cluster_df.sort_values('original_ids').query('probes == 0.0')[['original_ids','probes','site','allen_ontology']].head(100)",
   "id": "ee102ab10a2e35bd",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.565422Z",
     "start_time": "2025-02-08T18:15:01.563187Z"
    }
   },
   "cell_type": "code",
   "source": "# channel_df.query('probes == 0.0').head(200)",
   "id": "75cb847da910f2c4",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.573903Z",
     "start_time": "2025-02-08T18:15:01.566428Z"
    }
   },
   "cell_type": "code",
   "source": "# channel_df.query('probes== 1.0')[['probes','site','allen_ontology']].head()",
   "id": "49df5abad7ac935",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.623977Z",
     "start_time": "2025-02-08T18:15:01.621589Z"
    }
   },
   "cell_type": "code",
   "source": "# channel_df.query('probes==1.0').site.values",
   "id": "2fb34163ea155b50",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.723289Z",
     "start_time": "2025-02-08T18:15:01.720893Z"
    }
   },
   "cell_type": "code",
   "source": "# cluster_df.query('probes== 1.0').sort_values('site').site.values",
   "id": "31c65eae22a9e7a7",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.731432Z",
     "start_time": "2025-02-08T18:15:01.723289Z"
    }
   },
   "cell_type": "code",
   "source": "# cluster_df.query('probes== 0.0').sort_values('site').site.values",
   "id": "9c3571914167982e",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.832715Z",
     "start_time": "2025-02-08T18:15:01.830381Z"
    }
   },
   "cell_type": "code",
   "source": "# channel_df.query('probes== 0.0').sort_values('site').site.values",
   "id": "65788137bbd4a56d",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.839282Z",
     "start_time": "2025-02-08T18:15:01.832715Z"
    }
   },
   "cell_type": "code",
   "source": "# channel_df.query('probes== 1.0').sort_values('site').site.values",
   "id": "f5a36c7ec2153210",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-08T18:15:01.891068Z",
     "start_time": "2025-02-08T18:15:01.888430Z"
    }
   },
   "cell_type": "code",
   "source": "# channel_df.query('probes== 1.0').sort_values('raw_row').site.values",
   "id": "87466ab2f94ed452",
   "outputs": [],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
